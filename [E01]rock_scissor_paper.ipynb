{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공지능과 가위바위보 하기!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel/anaconda3/lib/python3.7/site-packages (7.0.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가위 이미지를 불러와서 28x28 사이즈로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  바위 이미지를 불러와서 28x28 사이즈로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\") \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 바위 이미지를 불러와서 28x28 사이즈로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffelrock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \",image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 600 입니다.\n",
      "x_train shape: (600, 28, 28, 3)\n",
      "y_train shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXj0lEQVR4nO2da4yc5XXH/2dm9uLd9W19w4CDAROKgcSkLm0FuaJQ4AtEaqrwIaIVqiM1kRIpHxqlH4L6oUJtkygfqkhOg0KiXKUkClJoG0oulFSN2KQOGExjY0Ns7+K1sde7673NzHv6YYdqQ/b5n83M7syoz/8nrWZ3zjzv+8w773/e2fk/5xxzdwgh/v9T6vQEhBDtQWIXIhMkdiEyQWIXIhMkdiEyodLOna1fv963bNuajJsZHc/C0ViE4eb3zYPhrldA81sIj0srz3sl45F2e7rZCFr7ubV+VizHq6+O4eLExLIbb0nsZnYXgM8BKAP4Z3d/mD1+y7at+NTf/W0yXq7wA1CppKdbqZTp2FKw7XKZj6/0puPR2FKptQ9Q5nw8E3Sl1EPHlsv8FIiemyF47kUtGSsKrqi6FzQeEhw3RhHsOopHb7IF/VDd/BvBXz34F8lY00fDzMoA/gnA3QD2ArjfzPY2uz0hxNrSyiXnVgDH3P24uy8A+AaAe1dnWkKI1aYVsV8B4OSSv0817vsNzOyAmY2Y2cj01FQLuxNCtEIrYl/uH4vf+ifM3Q+6+3533z+0fn0LuxNCtEIrYj8FYNeSv68EMNradIQQa0UrYn8GwHVmdrWZ9QL4AIDHVmdaQojVpmnrzd1rZvYRAP+GRevtEXd/no0xGKxI2wpWjzzfdLwoBcZo2gECAJTAvZR6lcwtsJCMWIav752OJ141AJSIfWbGt10JToGK8XipxONVrydjbsFrFnndLViS7tG5FrymgTtWD7YfP7nmYFttyWd398cBPN7KNoQQ7UHLZYXIBIldiEyQ2IXIBIldiEyQ2IXIBIldiExoaz47AID47JF5SSzbOO+6zH3NIkhgLpF4Efi9RZCyyJNEAQtSZEul9PbLHqSgRimqLcaZ3+zBtSZMcA3WENA00+B8Kdh5CqAwPjsP1l6sHen96souRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkQtuttzKxalgM4FZKVIEV9dasECfpt6UgXTFKUfXAQop8Iq+lx4f2VmBBea01C4rZjtErUgS2YQQrDx7Wb41SVIPJRymya1VKmm1XV3YhMkFiFyITJHYhMkFiFyITJHYhMkFiFyITJHYhMqGtPrvBULJ0V1EL3nvK1ENsvnUwAJQCn57uOxhbcn6Yw3bR9aiTKvGya0Gn1KAdaRHU4I66ldZ7yRqAIK3Yo/UL4dKJ5tOpiyDBNrbhg9e0AxmwurILkQkSuxCZILELkQkSuxCZILELkQkSuxCZILELkQlt9dkdhjrJ3bYS95OdteCNcsIDY9NJOWYgyo0O9h3l2geebBGUkmbbj0oiW+B1RwWdQ7uYvKSRz14EawAij59Wkm6xo3IRtemOyqKzua2RB9+S2M3sZQBTAOoAau6+fzUmJYRYfVbjyv5udz+3CtsRQqwh+p9diExoVewO4Adm9nMzO7DcA8zsgJmNmNnI1NRki7sTQjRLqx/jb3P3UTPbDuAJM3vR3Z9a+gB3PwjgIABcfc2eTjXAEiJ7Wrqyu/to43YcwHcB3LoakxJCrD5Ni93MBs1s/eu/A7gTwOHVmpgQYnVp5WP8DgDfbfiJFQBfc/d/ZQMcQJ16yoE3SeKVKF+9xfzjooX1AWwssAK/ODouzR/S4PVYwQai0UW6z3bko0c+fHTcSmx9QpRL32I8em6M2GcnDyDzalrs7n4cwFubHS+EaC+y3oTIBIldiEyQ2IXIBIldiEyQ2IXIhLa3bK552pKISgfDmp9u1PzXg1TOMnlf9KBtcVR2OJqdB16MEV+RpQUDAIL02chiitJ3aQptuO0WF1yS8dGWnZyni/FOWm9pmIZ0ZRciEyR2ITJBYhciEyR2ITJBYhciEyR2ITJBYhciE9pcStpRlNMpj4hSQVFNxirldCtoAChXuJddCszNajGfjs1xT3XdunU0bj3cCy+XAx+eeKuF85bLRRHEg0UCkd88GKT/UsJS0VHecnputVp0XJr3yQGgUuHSYsctWm/S7Nx0ZRciEyR2ITJBYhciEyR2ITJBYhciEyR2ITJBYhciE9rqs5dKhr7+9C4j/7Ao0j77/ELaB18cy5/qQA/36QfX9SZjvRU+dmpqisatzt9zS0EevxNPtxR49KWe9PMCgN4Kj9NyzQAwPZ0MVYKx0fqCyGev0fOJrPcA4stgsH6gXA7mRtcn8LG9pf5krETWqujKLkQmSOxCZILELkQmSOxCZILELkQmSOxCZILELkQmtNVnr9druDR5Lhnv70/7hwAw0N+XjPX28LFW475qfeESjU/OXEjGvM7XB+zYsYPvO6hRXo/WH5Cc9SLYNoLj4uB53x545QMkV78g7ZwBoDo/R+NzC+l1FwBQr6e3X+7hp35f/wCN9/Rxn/3iBF9bsVBLz30hOJ/Y2oZaPb3d8MpuZo+Y2biZHV5y37CZPWFmRxu3m6PtCCE6y0o+xn8JwF1vuO8TAJ509+sAPNn4WwjRxYRid/enAJx/w933Ani08fujAO5b5XkJIVaZZr+g2+HuYwDQuN2eeqCZHTCzETMbmQ7WiAsh1o41/zbe3Q+6+3533z+0fv1a704IkaBZsZ8xs50A0LgdX70pCSHWgmbF/hiABxq/PwDge6szHSHEWhH67Gb2dQDvArDVzE4B+BSAhwF8y8weBPBrAO9fyc5Kxn3XMslXBwDMpT1frwV+b1/aoweArTu20vhl27clY5s2baJjT58+TePVKn/e1cB3rRIvfS6ojz47F3jZM+l8dAAoghrnPp9+btG6isGBIRrfNMTr8bulvfBqnR+X6Rl+XCbOTdL4zsuvpPG5hfT+Z6q8NkO9Tnqwkzz7UOzufn8idEc0VgjRPWi5rBCZILELkQkSuxCZILELkQkSuxCZ0NYUVxR1FNNpy2LzMLewLiepotu3DNOxQ+u4zdMftNitkLLGlWKBjv29G6+ncQTWWggrg11wa2xulltM07MzNF6t8bn3L6SPzcVg+fT4eDodGgDOnuNruYy06R7auJGOHd7Ibb/Nm3mi54WJN6aT/CZeTp9v5VJQOrycvkaz8tq6sguRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCW312TcODeHud96ejJd4p1qUmGUcpCziEvd0a0GqZpm0NrYKf8+cHB+j8SpJWQSAXlJCGwDWbyZrDAa5X9wfHPO+dXzfFrQuxlzaZ9+8gc9tx1buZU9N8/Lfl2bTqaLTczyt+NzZszR+5jz30S9M8vUJ64bSz31gA18DUO5Ll7lm5bN1ZRciEyR2ITJBYhciEyR2ITJBYhciEyR2ITJBYhciE9rqs5cMGCRmeV9Q7rmf5aSTssEAgLlZHg580/OjJ5OxmSlebnl8nOddz1V5PnzUPngLyfMf3s7bRfcP8W33D/EuPr0DfPzE+JlkLHreZ87yfPYTr6RfEwB47Xy6zfZ8UENgoeALEOaC8t/X7r2JxnuIV94XrI0o9aZLaJdJ3QVd2YXIBIldiEyQ2IXIBIldiEyQ2IXIBIldiEyQ2IXIhDb77IbBvnReuJNcXACYvZD2wuemudd98Rz30c+OjdL4+Gi67fLFCxN0rDvPV58J1gCgQurCA9iy47JkbOtO7rNv3LKFxjcP81bWGzfzWv+bNqVzs+cXeGvi6eA17SlzL7yH1I0P5719J42vG9pA4zML/FyuklNidpafDwuX0rX+a6RFd3hlN7NHzGzczA4vue8hMzttZocaP/dE2xFCdJaVfIz/EoC7lrn/s+6+r/Hz+OpOSwix2oRid/enAPDPwEKIrqeVL+g+YmbPNj7mJ4uFmdkBMxsxs5FzZK2yEGJtaVbsnwdwLYB9AMYAfDr1QHc/6O773X3/1mFeQFAIsXY0JXZ3P+PudXcvAHwBwK2rOy0hxGrTlNjNbKkv8T4Ah1OPFUJ0B6HPbmZfB/AuAFvN7BSATwF4l5ntA+AAXgbwoRXtrVoFTqX97HlSYxwAzhI/e/QMr/M9Ns6/Yxx77TUaH301vf2zr/G864Wgpn0lqN2+MM9rkN+8983J2PGXjtKx24d5jfLLtnKffdMm7jdfZ+ntV4NrzYWgxsDvv+UtND69O72m48Wg93vvjito/IWxV2m8PMjrANRIkwR3fkKUirSHX5DthmJ39/uXufuL0TghRHeh5bJCZILELkQmSOxCZILELkQmSOxCZEJbU1zr9TrOT6ZbJ5848QodP0ZKMs/VeBrp+PmLNH70xAkav0DKRfevG6RjT7x0nMb3XLebxqfOc+vtx0//NBm7ehdP1XzhOX5c+vt4eu21V++m8fG+dAptqT9dEhkAqj28tPiF51+g8V5SYntgI7ccXzjMt73t2mtpfHKBl5q2GrHXnJe5ZhnTLKYruxCZILELkQkSuxCZILELkQkSuxCZILELkQkSuxCZ0FaffXpmFv/134eS8YLbi7g4n/Yuz7zGyzlPBGWJd77pahr/w2vSvuqVb9pFx37/+9+n8aef+gmNT0/yVM++nvR79uzsJTq27Lzk8b633kzjh4/8isYX1qe97r37bqFjT57lra6L2XRJZQB4266rkrHpeZ52vCFom2z8sAHV4GRGk2Y5ABTNjdWVXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMaKvPXjgwRfzJc6QlMwCcOp0u31utcV9z957raXxvUJZ43UDad714keeE3/7uO2h8w/Awjf/L49ynP3b018nYjk3cT+5LdzUGABw5xnPxozbbA96fjA1Pp2sbAMBCL89nP/TLX9L4tutvSMY27nwTHTs0wHPtR0/yUtL9G3i+vIGVkg58dprQng7pyi5EJkjsQmSCxC5EJkjsQmSCxC5EJkjsQmSCxC5EJrTVZ59dWMCRk6eT8QsXJ+n43r6BZGzPTem2xQCw66rdNH6pztvkjo2mfdW5uXk6dts23vb4HXfeQ+ODGzfR+NM//mEyNvLMz+jYoX5eF36aPzVUq9zHr+1K19Q/fo63TX73n9xF4z994UUa/8l//Gcy9uGP307HHnrxGI0P9nIfvh7ky5ulz7dSwc/FOs2FT4fCK7uZ7TKzH5nZETN73sw+2rh/2MyeMLOjjdvN0baEEJ1jJR/jawA+7u43APgjAB82s70APgHgSXe/DsCTjb+FEF1KKHZ3H3P3XzR+nwJwBMAVAO4F8GjjYY8CuG+tJimEaJ3f6Qs6M9sN4BYAPwOww93HgMU3BADbE2MOmNmImY3MBP/bCiHWjhWL3cyGAHwbwMfcnX+TtgR3P+ju+919/0A/T2wQQqwdKxK7mfVgUehfdffvNO4+Y2Y7G/GdAHgpUCFERwmtN1v0CL4I4Ii7f2ZJ6DEADwB4uHH7vWhbcwsLeOGVk8n49TfspeP33pROQ92wiZsBk9O8pPLMDC813U9SXC+7/Eo69hJp9wwAr7x6hsb33MjTb2+4OR2f/cw/0LFjp0/R+MAwtw2j47bhqnQ55zffcCMdu/4y3m767e+9k8b//cfpVtavkPMQAMoFvw4O9PE23ReD882cpLgy/6zxiHQoHVuJz34bgA8CeM7MXi/6/kksivxbZvYggF8DeP8KtiWE6BCh2N39aSCZac+rMgghugYtlxUiEyR2ITJBYhciEyR2ITJBYhciE9qa4to/OIS9f/DHyfiOy7mvOl9Op2O+NMq9ajNeM3njMPfp655+Xzx+cpSO3bSJp6iWe9LllgHg1Qm+YHHb5vT2777vT+nYHz75BI1fushbYe+58RoaX39lumTzFTekSz0DwMvjPAX2mr3cp991YiwZ++a3vpOMAcAd7+EeflHn5cMN/HwzT5c+5wmuoFs2lZIWQkjsQmSCxC5EJkjsQmSCxC5EJkjsQmSCxC5EJrTVZ6/09mLLrrTvOj23QMdPLKT95n5SZhoA+vt56d+ZKm89XBTpeGmQ5zbXStw5PX+Bty7evmULjV+cmUvG6j29dOwdd/Ey1jffdBONHzt2lMaLwfT1ZDRYP1AOWjZfqvM23bfcemsy9rWvfJOOnZjg6wt2X7WHxqemeD47PSWCdPYaM9NJPruu7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkQlt99nrhmCBeernMp1Mqpd+bFoIs4Oo8bz3FWugCQKWUzqVn8wKAmYUqjfcEPv3k7AyNG/FWBzcO07ElcK86ytUv9fH1CxhI+/xTk3x9QZnkfAPAhhKvA1C39Ovy9ne+k469cIHnq/dW0q3HAWBdP39NC2Km11vw2V0+uxBCYhciEyR2ITJBYhciEyR2ITJBYhciEyR2ITJhJf3ZdwH4MoDLABQADrr758zsIQB/CeBs46GfdPfH2bbcHdUa8RdJzjgAlEnB7MgnbzVelGvpeQW9vIvAhy8FfnJ6z/H4WlCEnKVGA0AJ/DWJjtvspfQagWqVP+++4Ljx1QtAL1kDsDmoEdATSGPzZr5+YWqS5+o7uc7Wg4R25tEzn30li2pqAD7u7r8ws/UAfm5mr3cW+Ky7/+MKtiGE6DAr6c8+BmCs8fuUmR0BcMVaT0wIsbr8Tv+zm9luALcA+Fnjro+Y2bNm9oiZLds/ycwOmNmImY3MXOKleoQQa8eKxW5mQwC+DeBj7j4J4PMArgWwD4tX/k8vN87dD7r7fnffPxCsARdCrB0rEruZ9WBR6F919+8AgLufcfe6uxcAvgAgXd1PCNFxQrHb4tetXwRwxN0/s+T+pS1X3wfg8OpPTwixWqzk2/jbAHwQwHNmdqhx3ycB3G9m+7BY+PZlAB+KNuQOzNdISeYStxzKJGzGbZxykAIbWUj1enrelRJvz1uP/K2AcjCehaPnHXlvLU6d24akDTYAFIGlOTsTpC0Tm7dU4a8ZCn7cpmZ4eu5cLTIGya4D641Zc05s2JV8G/80lm8ZTT11IUR3oRV0QmSCxC5EJkjsQmSCxC5EJkjsQmSCxC5EJrS1lLTD4cRn98BnLwrimwbpkGGaaGQok/zaKDXXg7khKOccWd1sjUCdpDyuhGj9QURPkS7BjeC4eMGPy8zMLN85aelsQbvn2aD898QUb+m8bh1fGs5SUVkMCFJcSUxXdiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhMkdiEywSJPb1V3ZnYWwCtL7toK4FzbJvC70a1z69Z5AZpbs6zm3K5y923LBdoq9t/audmIu+/v2AQI3Tq3bp0XoLk1S7vmpo/xQmSCxC5EJnRa7Ac7vH9Gt86tW+cFaG7N0pa5dfR/diFE++j0lV0I0SYkdiEyoSNiN7O7zOx/zOyYmX2iE3NIYWYvm9lzZnbIzEY6PJdHzGzczA4vuW/YzJ4ws6ON22V77HVobg+Z2enGsTtkZvd0aG67zOxHZnbEzJ43s4827u/osSPzastxa/v/7GZWBvArAO8FcArAMwDud/cX2jqRBGb2MoD97t7xBRhm9g4A0wC+7O43Ne77ewDn3f3hxhvlZnf/6y6Z20MApjvdxrvRrWjn0jbjAO4D8Ofo4LEj8/oztOG4deLKfiuAY+5+3N0XAHwDwL0dmEfX4+5PATj/hrvvBfBo4/dHsXiytJ3E3LoCdx9z9180fp8C8Hqb8Y4eOzKvttAJsV8B4OSSv0+hu/q9O4AfmNnPzexApyezDDvcfQxYPHkAbO/wfN5I2Ma7nbyhzXjXHLtm2p+3SifEvlxRs27y/25z97cBuBvAhxsfV8XKWFEb73axTJvxrqDZ9uet0gmxnwKwa8nfVwIY7cA8lsXdRxu34wC+i+5rRX3m9Q66jdvxDs/n/+imNt7LtRlHFxy7TrY/74TYnwFwnZldbWa9AD4A4LEOzOO3MLPBxhcnMLNBAHei+1pRPwbggcbvDwD4Xgfn8ht0SxvvVJtxdPjYdbz9ubu3/QfAPVj8Rv4lAH/TiTkk5nUNgF82fp7v9NwAfB2LH+uqWPxE9CCALQCeBHC0cTvcRXP7CoDnADyLRWHt7NDcbsfiv4bPAjjU+Lmn08eOzKstx03LZYXIBK2gEyITJHYhMkFiFyITJHYhMkFiFyITJHYhMkFiFyIT/hf0q4souUTSEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (600, 28, 28, 3)\n",
      "After Reshape - x_train_reshaped shape: (600, 28, 28, 3)\n",
      "Epoch 1/10\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0637 - accuracy: 0.4633\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.6083\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7996 - accuracy: 0.6550\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7142 - accuracy: 0.6883\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.7450\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.7617\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7783\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.8283\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8650\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd0b57edd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 600 입니다.\n",
      "Before Reshape - x_test_norm shape: (600, 28, 28, 3)\n",
      "After Reshape - x_test_reshaped shape: (600, 28, 28, 3)\n",
      "Epoch 1/10\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8550\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8850\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8800\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.9133\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2127 - accuracy: 0.9417\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.1434 - accuracy: 0.9700\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fccb0e0b150>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0\n",
    "\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_test_reshaped, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련시킨 model을 사용하여 test_accuracy를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 0s - loss: 0.1429 - accuracy: 0.9633\n",
      "test_loss: 0.14290012419223785 \n",
      "test_accuracy: 0.9633333086967468\n"
     ]
    }
   ],
   "source": [
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
